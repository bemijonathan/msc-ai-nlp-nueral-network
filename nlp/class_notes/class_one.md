## NLP (Natural Language Processing)

### Materials
Main external materials for this module
- http://www.nltk.org/book/ 
- https://amzn.eu/d/37qYBfc 


### **Learning Outcomes**

- Introduction to module
- Categorizing and tagging words
- Learning to classify text
- Extracting information from text
- Analysing sentence structure
- Feed forward networks for NLP
- Chatbot based on pytorch
- Classifying names with character level RNN on pytorch 
- Translation with a sequence to sequence networks and attention on pytorch
- Advanced topics in NLP

This course is mostly practical based hence you need to learn to set up a standard python Machine learning environment

- https://www.youtube.com/watch?v=mpk4Q5feWaw
- https://www.youtube.com/watch?v=yTJxDzqo4fQ&t=286s 
- https://www.youtube.com/watch?v=qI3P7zMMsgY 

Natural language processing (NLP) is an area of
artificial intelligence which aids computers understand,
interpret and manipulate human language.

objectives of NLP includes

- Understand and analyze human language
- Generate human-like text or speech
- Facilitate human-computer interaction using natural language

### Approaches to NLP
There are two approaches to NLP 
- Classic approach (NLTK): This approach involves the use of traditional linguistic and statistical methods, ussually the use of  Rule based systems, statistical models, feature engineering etc. 
example of these techniques include 
    - Regular expressions 
    - P-O-S tagging (parts of speech)
    - Named Entity Recognition (tagging words to organisation like company, school etc.)
    - Topic modeling (identifying theme and topics)
    
    [NLTK](https://www.nltk.org/) is the choice of library here others include [spacy](https://spacy.io/)
- Deep learning based: Pytorch  is an open-source machine learning library developed by Facebook's AI Research lab. It's widely used for various artificial intelligence tasks, particularly in deep learning and natural language processing. Here's an overview of PyTorch:

Core Concept:
PyTorch provides tensor computations with strong GPU acceleration and a tape-based autograd system for building neural networks.
Key Features:

Dynamic Computational Graphs: Allows for more flexible model architectures
Imperative Programming Style: More intuitive for many developers
Native Python Integration: Seamlessly works with Python data structures
GPU Support: Efficiently utilizes GPU for faster computations
Extensive Ecosystem: Rich set of tools and libraries